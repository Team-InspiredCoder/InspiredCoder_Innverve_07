{% load static %}


<!DOCTYPE html>
<html lang="en">

<head>



    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
    <!-- <link rel="icon" type="image/x-icon" href="{% static 'images/favicon.jfif' %}"> -->

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css">
    <!-- <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js"></script> -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js"></script>
    <script src="https://code.jquery.com/jquery-3.4.1.min.js"
        integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>

    <!-- For Face Detection -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface"></script>

    <link rel="stylesheet" href="/static/interview/interview_page.css" />

    <title>Interview UI</title>

</head>



<body>

    <audio id="myAudio" loop>
        <source src="#" type="audio/mp3">
        </source>
    </audio>


    <div id="timer_div">
        <p id="Timer"></p>
    </div>

    <div class="main_popup">
        <div class="popup">
            <span class="material-icons" style="color: red;">
                warning
            </span>
            <h6 id="Error_Messgae"></h6>

        </div>
    </div>


    {% csrf_token %}

    <video id="web_cam" autoplay="" height="100%" width="100%" muted="" style="visibility:visible;"></video>
    <a id="dnld_video_link"></a>

    <div id="caption_div">
        <h5 id="caption_text"></h5>
    </div>

    <div class="main">

        <video width="100%" height="100%" id="MainVideo">
            <source src="#" type="video/mp4">
        </video>


        <canvas id="canvas" width="600px" height="400px" style="visibility: hidden;"></canvas>



        <!-- <br> -->

        <div class="buttons_div">
            <span id="download_btn" class="material-icons" onclick="gotohome()">home</span>

            <span id="mic_btn" class="material-icons" onclick="mic_toggle()">mic</span>
            <span id="camera_btn" class="material-icons" onclick="camera_toggle()">videocam</span><span><a id="download_Video_of_Interview"><br><br><button type="button" class="Download_class" href=""> <b> Download
                            Videos </b></button></a></span>
            
            <!-- <span id="end_meet_btn" class="material-icons" onclick="end_call()">call</span> -->
            <span id="caption_btn" class="material-icons" onclick="caption_toggle()">closed_caption</span>


            <!-- <span id="more_options" class="material-icons" >more_vert</span> -->
        </div>
    </div>

    <!-- 
    <div class="start_meet_div">

        <div class="start_meet">

            <p class="instructions_lines">Please grant all permissions for better experience ! <br> </p>
            <p class="instructions_lines" style="font-weight: 300;">
            Please read <a href="pp">Privacy Policy</a> & <a href="tc">Terms of Use</a>
            </p>

            <p class="instructions_lines"> <input id="agree_to_terms" type="checkbox">   I have read all the instructions and agree to all conditions.!</p>

            <br>
            <button class="start_btn" id="Start_Interivew_Id">
            <b>Start Interview</b>
            </button>
            <style>
                #start_int_load{
                    height: 100%;

                }

            </style>
            <button id="start_btn_id_load" style="text-align: center; color: white; background-color: black;" type="button" class="start_btn_load">
                <video id="start_int_load" class="loading_video" loop muted autoplay>
                    <source src="{% static 'videos/loading.mp4' %}" type="video/mp4">

                </video>

            </button>

            <br><br><br>
            <div id="return_home_1" style="margin-right: 20px;" onclick="gotohome()">
                <span style="font-size: 40px;" id="download_btn" class="material-icons">home</span>
            <h5 style="color: white;">Home</h5>
            </div>

            <div>
                <p id="permission_denied"></p>
            </div>

        </div>

    </div>
 -->

    <!-- 
    <div class="close_meet_div">

        <div class="close_meet" id="Get_Report_Card">
            <button class="close_btn">
                <b>Get Report</b>
            </button>
            <div>
                <span><a id="download_Video_of_Interview" ><br><br><button  type="button" class="Download_class" href=""> <b> Download Videos </b></button></a></span>

            </div>
           <br><br>
        <div id="final_icon_div">

            <div id="return_home" style="margin-right: 20px;" onclick="gotohome()">
                <span style="font-size: 40px;" id="download_btn" class="material-icons">home</span>
            <h5 style="color: white;">Home</h5>
            </div>

            <div id="restart_again" style="margin-left: 20px;"  onclick="restart_interview()">
                <span style="font-size: 40px;" id="download_btn" class="material-icons">restart_alt</span>
            <h5 style="color: white;">Start Again</h5>
            </div>

        </div>

        </div>

    </div>
 -->





    <!-- scripts -->

    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface"></script>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>

    <script type="text/javascript">
        var tcount = 0;

            // const myInterval = setInterval(nextQuestionTrigger, 5000);


            function nextQuestionTrigger() {
                console.log("\nNext Question Trigger !");
            }

            // function stopTrigger() {
            //     clearInterval(myInterval);
            // }


            function runSpeechRecognition() {

                var prev_index = null;
                var triggerEnable = true;

                var SpeechRecognition = SpeechRecognition || webkitSpeechRecognition;
                var recognition = new SpeechRecognition();
                recognition.continuous = true;
                recognition.interimResults = false;

                recognition.onstart = function () {
                    console.log("\nRecognition has started !");
                };

                recognition.onend = function () {
                    console.log("\nRecognition has ended !");
                    recognition.stop();
                    tcount = 0;
                    recognition.start();
                }


                recognition.onresult = function (event) {

                    console.log("\nRecognized speech !");

                    var current = event.resultIndex;

                    if (current == prev_index && triggerEnable) {
                        triggerEnable = false;
                    }

                    if (current != prev_index) {
                        // stopTrigger();
                        prev_index = current;
                        triggerEnable = true;

                        var transcript = event.results[current][0].transcript;
                        var confidence = event.results[current][0].confidence;

                        console.log("\nResult :: " + JSON.stringify(event.results));
                        console.log("\ntranscript :: " + transcript);
                    }

                };

                recognition.start();

            }


            // calling speech recognition
            runSpeechRecognition();






            // *************************** Video *****************************


            // let video = document.getElementById("video_element");
            let model;
            let canvas = document.getElementById("canvas")
            let ctx = canvas.getContext("2d")
            let cls_cam;
            let shouldStop = false;
            function closing_camera() {
                shouldStop = true;
                const video = document.getElementById('web_cam');

                const mediaStream = video.srcObject;
                const tracks = mediaStream.getTracks();

                // Tracks are returned as an array, so if you know you only have one, you can stop it with:
                tracks[0].stop();
                // Or stop all like so:
                tracks.forEach(track => track.stop())


                cls_cam.stop();

            }





            const setupCamera = () => {
                navigator.mediaDevices
                    .getUserMedia({
                        video: { width: 600, height: 400 },
                        audio: false,
                    })
                    .then((stream) => {
                        video.srcObject = stream;
                    });
            };


            const videoElement = document.getElementById('web_cam');
            const parts2 = [];

            async function recordVideo() {

                const mimeType = 'video/webm';
                shouldStop = false;
                const constraints = {
                    video: {
                        "width": {
                            "min": 640,
                            "max": 1024
                        },
                        "height": {
                            "min": 480,
                            "max": 768
                        }
                    }
                };



                const stream = await navigator.mediaDevices.getUserMedia(constraints);
                videoElement.srcObject = stream;
                handleRecord({ stream, mimeType })






                //setTimeout(recordScreen, 1000);
            }


            async function recordScreen() {
                console.log("In recordScreen function!!");

                const mimeType = 'video/webm';
                shouldStop = false;
                const constraints = {
                    video: {
                        cursor: 'motion'
                    }
                };
                if (!(navigator.mediaDevices && navigator.mediaDevices.getDisplayMedia)) {
                    return window.alert('Screen Record not supported!')
                }
                let stream = null;
                console.log("Ask  Screen Permission...")
                const displayStream = await navigator.mediaDevices.getDisplayMedia({ video: { cursor: "motion" }, audio: { 'echoCancellation': true } });
                if (1) {
                    const audioContext = new AudioContext();

                    const voiceStream = await navigator.mediaDevices.getUserMedia({ audio: { 'echoCancellation': true }, video: false });
                    const userAudio = audioContext.createMediaStreamSource(voiceStream);

                    const audioDestination = audioContext.createMediaStreamDestination();
                    userAudio.connect(audioDestination);

                    if (displayStream.getAudioTracks().length > 0) {
                        const displayAudio = audioContext.createMediaStreamSource(displayStream);
                        displayAudio.connect(audioDestination);
                    }

                    const tracks = [...displayStream.getVideoTracks(), ...
                        audioDestination.stream.getTracks()]
                    stream = new MediaStream(tracks);
                    handleRecord({ stream, mimeType })
                } else {
                    stream = displayStream;
                    handleRecord({ stream, mimeType });
                };


                // main_fun()

            }

            const handleRecord = function ({ stream, mimeType }) {
                // startRecord()
                console.log("In handle Record!!");
                let recordedChunks = [];
                stopped = false;
                const mediaRecorder = new MediaRecorder(stream);
                cls_cam = mediaRecorder;

                mediaRecorder.ondataavailable = function (e) {
                    if (e.data.size > 0) {
                        recordedChunks.push(e.data);
                    }

                    if (shouldStop === true && stopped === false) {
                        mediaRecorder.stop();
                        stopped = true;
                    }
                };

                mediaRecorder.onstop = function () {
                    console.log("In On Stop Of screen Sharing!!")
                    const blob = new Blob(recordedChunks, {
                        type: mimeType
                    });
                    recordedChunks = []
                    const filename = "InterviewVideo"
                    downloadLink.href = URL.createObjectURL(blob);
                    downloadLink.download = `${filename || 'recording'}.webm`;
                    //   stopRecord();
                    videoElement.srcObject = null;
                };

                mediaRecorder.start(200);
            };


            function check_face_probability(face_probability) {
                face_probability = face_probability * 100

                var btn_status = $("#camera_btn").text();
                btn_status = "videocam"
                if (btn_status == "videocam") {

                    if (face_probability < 80) {
                        console.log("You are not visibile on Camera Please check your face position otherwise your interview will be terminated");
                    }
                    else if (face_probability < 95) {
                        console.log("You are not properly visible either adjust your camera or change your position");
                    }
                    else {
                        console.log("Good Position")
                    }
                }
                else {
                    console.log("Camera is closed")
                }

            }

            Web_Cam_fun()
            recordScreen()
            function Web_Cam_fun() {

                navigator.mediaDevices.getUserMedia({ audio: true, video: true }).then(stream => {

                    videoElement.srcObject = stream;

                    MediaRecorder_new = new MediaRecorder(stream);
                    MediaRecorder_new.start(1000);
                    MediaRecorder_new.ondataavailable = function (e) {
                        parts2.push(e.data);
                    }


                });
            }

            const downloadLink = document.getElementById('download_Video_of_Interview');
            document.getElementById("download_Video_of_Interview").onclick = function () {
                shouldStop = true;
                closing_camera();
                MediaRecorder_new.stop();
                const blob_new = new Blob(parts2, {
                    type: "video/webm"
                })
                const url_new = URL.createObjectURL(blob_new);
                const a_new = document.createElement("a");
                document.body.appendChild(a_new);
                a_new.href = url_new;
                a_new.download = "Video.webm";
                a_new.click();




            }

            const detectFaces = async () => {

                const prediction = await model.estimateFaces(videoElement, false);

                try {

                    face_probability = prediction[0].probability;
                    check_face_probability(face_probability)
                    console.log(face_probability * 100)

                }
                catch (error) {

                    var btn_status = $("#camera_btn").text();
                    btn_status = "videocam"
                    error_counter = 0
                    can_display_popup = false

                    if (btn_status == "videocam") {
                        if (error.name == "TypeError") {
                            var aud = document.getElementById("myAudio");

                            if (error_counter >= 3 && can_display_popup) {
                                //alert(error_counter)
                                //$("#myAudio").attr("loop")

                                console.log("Your Video is terminating")

                            }
                            else {

                                // showFacepopup("Your are not visible at all");
                                console.log("You are not visible t all")
                            }
                            if (can_display_popup) {
                                error_counter = error_counter + 1
                                console.log("Error_Counter:", error_counter)
                                console.log("can_display_popup val:", can_display_popup)
                            }
                            console.log(error_counter)
                        }
                    }
                    else {
                        console.log("Camera is closed in Catch block")
                    }
                }

                ctx.drawImage(videoElement, 0, 0, 600, 400);
                prediction.forEach((pred) => {
                    ctx.beginPath();
                    ctx.lineWidth = "4";
                    ctx.strokeStyle = "blue"
                    ctx.rect(
                        pred.topLeft[0],
                        pred.topLeft[1],
                        pred.bottomRight[0] - pred.topLeft[0],
                        pred.bottomRight[1] - pred.topLeft[1]

                    );
                    //ctx.stroke();


                });
            };



            videoElement.addEventListener("loadeddata", async () => {
                console.log("InloadedData Listener")

                model = await blazeface.load();
                setInterval(detectFaces, 5000)
            });




        

    </script>



</body>


</html>